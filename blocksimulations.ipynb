{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###initialise params\n",
    "random.seed(100)\n",
    "n_transactions = 1000\n",
    "scenario = 100\n",
    "datafilename= 'initial_data.csv'\n",
    "no_of_fake_feedback = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inital_dataset(n_transactions, datafilename):\n",
    "    interactions2 = [(random.randrange(100, 128), random.randrange(110, 116), random.uniform(0, 1), random.uniform(0, 1), 'G') for i in range(n_transactions)]\n",
    "    ##cleaning repetion\n",
    "    dt = pd.DataFrame(interactions2, columns=['Consumer', 'Producer', 'Consumerrating', 'Producerrating', 'TAG'])\n",
    "    dt = dt[dt['Consumer'] != dt['Producer']]\n",
    "    dt.reset_index(drop=True, inplace=True)\n",
    "    dt = dt.sort_values('Consumer', ignore_index=True)\n",
    "    \n",
    "    uniqueid1list = dt.Consumer.unique().tolist()\n",
    "    print(uniqueid1list)\n",
    "    indexlist = []\n",
    "    for i in uniqueid1list:\n",
    "        for index,row in dt.iterrows():\n",
    "            row = row.copy()\n",
    "            if row['Producer'] == i: #and index not in indexlist\n",
    "                dt.loc[index, 'Producer'] = row['Consumer']\n",
    "                dt.loc[index, 'Consumer'] = row['Producer']\n",
    "    dt.to_csv(datafilename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scenario(scenario, datafilename, no_of_fake_feedback):\n",
    "    dt = pd.read_csv(datafilename)\n",
    "    \n",
    "    datafinalfilename = 'scenario_'+str(scenario)+'_data.csv'\n",
    "    #attack scenario\n",
    "    dt.head(1).Consumer.item()\n",
    "    for i in range(no_of_fake_feedback):\n",
    "        if scenario == 1:\n",
    "            \n",
    "            new_row = {'Consumer': dt.head(1).Consumer.item(), 'Producer':dt.head(1).Producer.item(), 'Consumerrating':1, 'Producerrating':random.uniform(0, 1), 'TAG':'F'}\n",
    "            \n",
    "        elif scenario == 2:\n",
    "            new_row = {'Consumer': dt.head(1).Consumer.item(), 'Producer':dt.head(1).Producer.item(), 'Consumerrating':0.001, 'Producerrating':random.uniform(0, 1), 'TAG':'F'}\n",
    "        elif scenario == 3:\n",
    "            if (i > no_of_fake_feedback * 0.2) :\n",
    "                new_row = {'Consumer': dt.head(1).Consumer.item(), 'Producer':dt.head(1).Producer.item(), 'Consumerrating':1, 'Producerrating':random.uniform(0, 1), 'TAG':'F'}\n",
    "            else:\n",
    "                new_row = {'Consumer': dt.head(1).Consumer.item(), 'Producer':dt.head(1).Producer.item(), 'Consumerrating':0.001, 'Producerrating':random.uniform(0, 1), 'TAG':'F'}\n",
    "        elif scenario == 4:\n",
    "            if (i > no_of_fake_feedback * 0.2) :\n",
    "                new_row = {'Consumer': dt.head(1).Consumer.item(), 'Producer':dt.head(1).Producer.item(), 'Consumerrating':0.001, 'Producerrating':random.uniform(0, 1), 'TAG':'F'}\n",
    "            else:\n",
    "                new_row = {'Consumer': dt.head(1).Consumer.item(), 'Producer':dt.head(1).Producer.item(), 'Consumerrating':1, 'Producerrating':random.uniform(0, 1), 'TAG':'F'}\n",
    "        elif scenario == 5:\n",
    "            if (i == 1) :\n",
    "                new_row = {'Consumer': dt.head(1).Consumer.item(), 'Producer':106, 'Consumerrating':random.uniform(0, 1), 'Producerrating':random.uniform(0, 1), 'TAG':'F'}\n",
    "        elif scenario == 6:\n",
    "            if (i > no_of_fake_feedback * 0.5) :\n",
    "                new_row = {'Consumer': dt.head(1).Consumer.item(), 'Producer':dt.head(1).Producer.item(), 'Consumerrating':0.001, 'Producerrating':1, 'TAG':'F'}\n",
    "            else:\n",
    "                 new_row = {'Consumer': dt.head(1).Consumer.item(), 'Producer':dt.head(1).Producer.item(), 'Consumerrating':1, 'Producerrating':0.001, 'TAG':'F'}\n",
    "    #     elif scenario == 7:\n",
    "            ##TODO set neighbors/advisors to 02\n",
    "        dt = dt.append(new_row, ignore_index=True)\n",
    "        target_test_user = 115\n",
    "        if (i <= int(no_of_fake_feedback/4)):\n",
    "            new_row2 = {'Consumer': target_test_user, 'Producer':dt.head(1).Producer.item(), 'Consumerrating':random.uniform(0, 1), 'Producerrating':random.uniform(0, 1), 'TAG':'AG'}\n",
    "            dt = dt.append(new_row2, ignore_index=True)\n",
    "            new_row3 = {'Consumer': target_test_user-1, 'Producer':dt.head(1).Producer.item(), 'Consumerrating':random.uniform(0, 1), 'Producerrating':random.uniform(0, 1), 'TAG':'AG'}\n",
    "            dt = dt.append(new_row3, ignore_index=True)\n",
    "            new_row4 = {'Consumer': target_test_user-2, 'Producer':dt.head(1).Producer.item(), 'Consumerrating':random.uniform(0, 1), 'Producerrating':random.uniform(0, 1), 'TAG':'AG'}\n",
    "            dt = dt.append(new_row4, ignore_index=True)\n",
    "            new_row5 = {'Consumer': target_test_user-3, 'Producer':dt.head(1).Producer.item(), 'Consumerrating':random.uniform(0, 1), 'Producerrating':random.uniform(0, 1), 'TAG':'AG'}\n",
    "            dt = dt.append(new_row5, ignore_index=True)\n",
    "            new_row6 = {'Consumer': target_test_user-4, 'Producer':dt.head(1).Producer.item(), 'Consumerrating':random.uniform(0, 1), 'Producerrating':random.uniform(0, 1), 'TAG':'AG'}\n",
    "            dt = dt.append(new_row6, ignore_index=True)\n",
    "            new_row7 = {'Consumer': target_test_user-5, 'Producer':dt.head(1).Producer.item(), 'Consumerrating':random.uniform(0, 1), 'Producerrating':random.uniform(0, 1), 'TAG':'AG'}\n",
    "            dt = dt.append(new_row7, ignore_index=True)\n",
    "                \n",
    "        dt.to_csv(datafinalfilename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'initial_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1ead64ab70b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_scenario\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatafilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_of_fake_feedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-5bb97623fea8>\u001b[0m in \u001b[0;36mcreate_scenario\u001b[0;34m(scenario, datafilename, no_of_fake_feedback)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_scenario\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatafilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_of_fake_feedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdatafinalfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'scenario_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#attack scenario\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/anaka/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/anaka/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/anaka/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/anaka/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/anaka/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'initial_data.csv'"
     ]
    }
   ],
   "source": [
    "create_scenario(scenario, datafilename, no_of_fake_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-db6d3445a831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Consumer'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muser\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Consumer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Consumer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Producer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dt' is not defined"
     ]
    }
   ],
   "source": [
    "##seeing the data\n",
    "user = 'Consumer'\n",
    "if user == 'Consumer':\n",
    "    vd = dt.groupby(['Consumer', 'Producer'])\n",
    "for k, uid in vd:\n",
    "    print(uid)\n",
    "\n",
    "##func one\n",
    "def get_uid(vd, phi, decay, user):\n",
    "    newDF = pd.DataFrame()\n",
    "        \n",
    "    for k, uid in vd:\n",
    "        itr_list = uid[user+'rating'].tolist()\n",
    "#         print(itr_list)\n",
    "        cum_rj = 0\n",
    "        cum_sj = 0\n",
    "        exp_val_n = len(itr_list)\n",
    "        count = 0\n",
    "        sj_list = []\n",
    "        rj_list = []\n",
    "        cum_sj_list = []\n",
    "        cum_rj_list = []\n",
    "        \n",
    "#         for i in itr_list:\n",
    "        print('=========================================================')\n",
    "        for index, row in uid.iterrows():\n",
    "            count += 1\n",
    "            rj = ((1- row[user+'rating']) * phi) * (decay **(exp_val_n - count)) #disatisfaction\n",
    "            sj = ((1+ row[user+'rating']) * phi) * (decay **(exp_val_n - count)) #satisfaction\n",
    "            cum_rj += rj\n",
    "            cum_sj += sj\n",
    "            \n",
    "\n",
    "#             print('rj ='+ str(rj)+', sj = '+str(sj))\n",
    "            sj_list.append(sj)\n",
    "            rj_list.append(rj)\n",
    "            cum_sj_list.append(cum_sj)\n",
    "            cum_rj_list.append(cum_rj)\n",
    "            \n",
    "            \n",
    "        \n",
    "#         print('vendor = '+ str(k)+', st ='+ str(rj)+', ds = '+str(sj))\n",
    "        uid[user+'dis'] = rj_list  #disatisfaction list\n",
    "        uid[user+'sat'] = sj_list #satisfaction list\n",
    "        uid[user+'cum_dis'] = cum_rj_list #cummilative disatisfaction list\n",
    "        uid[user+'cum_sat'] = cum_sj_list #cummilative satisfaction list\n",
    "        \n",
    "\n",
    "        print(uid)\n",
    "        newDF = newDF.append(uid, ignore_index = True)\n",
    "    return newDF\n",
    "\n",
    "##setting decay and calling function one\n",
    "\n",
    "df = get_uid(vd, phi, decay, user)\n",
    "\n",
    "##getting ready to call again\n",
    "user = 'Producer'\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# df\n",
    "cd = df.groupby(['Consumer', 'Producer'])\n",
    "df = get_uid(cd, phi, decay, user)\n",
    "\n",
    "###reseting and grouping df\n",
    "user = 'Consumer'\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df\n",
    "\n",
    "cd = df.groupby(['Consumer'])\n",
    "\n",
    "##  function two\n",
    "def honesty(df, user='Consumer'):\n",
    "    honDF = pd.DataFrame()\n",
    "    for k, af in df:\n",
    "        print(af)\n",
    "        hon_li = []\n",
    "        cum_cumsat = 0\n",
    "        cum_cumdis = 0\n",
    "        for index, row in af.iterrows():\n",
    "            hon = 0\n",
    "            cum_cumsat += row['Producer'+ 'cum_sat']\n",
    "            cum_cumdis += row['Producer'+ 'cum_dis']\n",
    "#             hon = cum_cumsat / (cum_cumsat + cum_cumdis)\n",
    "            hon = 1 - (cum_cumdis / (cum_cumsat + cum_cumdis))\n",
    "            print('hon')\n",
    "            print(hon)\n",
    "            hon_li.append(hon)\n",
    "\n",
    "        af['honesty'] = hon_li\n",
    "        print(af)\n",
    "        honDF = honDF.append(af, ignore_index = True)\n",
    "    return honDF\n",
    "\n",
    "##calling honesty\n",
    "hon_df = honesty(cd) #for adviser\n",
    "\n",
    "#func three\n",
    "def bayes(df, user='Consumer'):\n",
    "    honDF = pd.DataFrame()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    cd = df.groupby(['Consumer'])\n",
    "    for k, af in cd:\n",
    "        print(af)\n",
    "        hon_li = []\n",
    "        cum_cumsat = 0\n",
    "        cum_cumdis = 0\n",
    "        for index, row in af.iterrows():\n",
    "            expectedtrust = 0\n",
    "            initr = 0\n",
    "            inits = 0\n",
    "            cum_cumsat += row['Consumer'+ 'cum_sat']\n",
    "            cum_cumdis += row['Consumer'+ 'cum_dis']\n",
    "#             hon = cum_cumsat / (cum_cumsat + cum_cumdis)\n",
    "            expectedtrust =  (initr + cum_cumsat) / (initr + inits + cum_cumsat + cum_cumdis)\n",
    "            print('expectedtrust')\n",
    "            print(expectedtrust)\n",
    "            hon_li.append(expectedtrust)\n",
    "\n",
    "        af['bayesT'] = hon_li\n",
    "        print(af)\n",
    "        honDF = honDF.append(af, ignore_index = True)\n",
    "    return honDF\n",
    "\n",
    "bdf = bayes(hon_df)\n",
    "\n",
    "#range 0-1\n",
    "def get_belief_implicit(cd, epsilon, user):\n",
    "#     tricky here, col.sum would result different than len(col)\n",
    "\n",
    "    newdDF = pd.DataFrame()\n",
    "    for k, af in cd:\n",
    "        print(af)\n",
    "        \n",
    "\n",
    "        dbis = []\n",
    "        bellis = []\n",
    "        unlis = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        for index, row in af.iterrows():\n",
    "            cum_dis = 0\n",
    "            cum_sat = 0\n",
    "            total_sat_dit = 0\n",
    "            den = 0\n",
    "            \n",
    "            cum_dis = row[user+'cum_dis'] \n",
    "            cum_sat = (row[user+'cum_sat'])\n",
    "\n",
    "\n",
    "            print('cum_dis')\n",
    "            print(cum_dis)\n",
    "            print('cum_sat')\n",
    "            print(cum_sat)\n",
    "            print('total')\n",
    "            total_sat_dit = cum_dis+cum_sat\n",
    "            den = total_sat_dit + epsilon \n",
    "            print(total_sat_dit)\n",
    "            belief = cum_sat /(den)\n",
    "            disbelief = cum_dis /(den)\n",
    "            uncertainity = epsilon / (den)\n",
    "            \n",
    "            dbis.append(disbelief)\n",
    "            bellis.append(belief)\n",
    "            unlis.append(uncertainity)\n",
    " \n",
    "\n",
    "        af[user+'bel'] = bellis\n",
    "        af[user+'disbel'] = dbis\n",
    "        af[user+'unc'] = unlis\n",
    "\n",
    "        print(af)\n",
    "        newdDF = newdDF.append(af, ignore_index = True)\n",
    "\n",
    "\n",
    "    return newdDF\n",
    "\n",
    "user = 'Consumer'\n",
    "bdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "cd = bdf.groupby(['Consumer'])\n",
    "\n",
    "\n",
    "df_dbu =get_belief_implicit(cd,uncertainity, user)\n",
    "\n",
    "def distancematrix(df):\n",
    "    uniqueid1list = df.Consumer.unique().tolist()\n",
    "    comb = list(itertools.combinations(uniqueid1list,2))\n",
    "    distance_matrix = [[0 for i in range(len(uniqueid1list))] for j in range(len(uniqueid1list))]\n",
    "    sim_matrix = [[0 for i in range(len(uniqueid1list))] for j in range(len(uniqueid1list))]\n",
    "    print(distance_matrix)\n",
    "    print(comb)\n",
    "    print(uniqueid1list)\n",
    "    \n",
    "    idxtoid = {}\n",
    "    idtoidx = {}\n",
    "    count = 0\n",
    "    for i in uniqueid1list:\n",
    "        idxtoid[count] = i\n",
    "        idtoidx[i] = count #mostly used\n",
    "        count += 1\n",
    "\n",
    "    cd = df.groupby(['Consumer', 'Producer'])\n",
    "\n",
    "    \n",
    "    distance_li = []\n",
    "    normalized_dist = []\n",
    "    \n",
    "    ##initializing vendor list\n",
    "    vendors = {}\n",
    "    cm_vendors = {}\n",
    "    \n",
    "    comv_advisors = {}\n",
    "    for i in uniqueid1list:\n",
    "        v = []\n",
    "        for x, af in cd:\n",
    "            if(x[0]==i):\n",
    "#                 print(x[1])\n",
    "                v.append(x[1])\n",
    "        vendors[i] = v    \n",
    "    \n",
    "    \n",
    "\n",
    "    for j in uniqueid1list:\n",
    "        com_ad = []\n",
    "        for k in uniqueid1list:\n",
    "            if( j!= k):\n",
    "                print('===================pairs================')\n",
    "                print('requestor '+str(j)+' vendors ='+str(vendors[j]))\n",
    "                print('advisor '+str(k)+' vendors ='+str(vendors[k]))\n",
    "                comm_vendors =  [v for v, u in zip(vendors[j], vendors[k]) if u == v]\n",
    "                \n",
    "                print('common vendors ='+str(comm_vendors))\n",
    "                cum_dist = 0\n",
    "                meand = 0\n",
    "                \n",
    "                print('searchin for vendor entries===')\n",
    "                for cv in comm_vendors:\n",
    "                    \n",
    "                    nonsqrt = 0\n",
    "                    dist = 0\n",
    "                    for x, af in cd:\n",
    "                        if(x[0]==j and x[1]==cv):\n",
    "                            print('set i entry')\n",
    "                            a_bel = 0\n",
    "                            a_disbel = 0\n",
    "                            a_unc = 0\n",
    "                            print(x)\n",
    "#                             print(af.Consumerbel.tail(1))\n",
    "#                             print(af.Consumerdisbel.tail(1))\n",
    "#                             print(af.Consumerunc.tail(1))\n",
    "                            a_bel = af.Consumerbel.tail(1).item()\n",
    "                            a_disbel = af.Consumerdisbel.tail(1).item()\n",
    "                            a_unc = af.Consumerunc.tail(1).item()\n",
    "                        if(x[0]==k and x[1]==cv):\n",
    "                            print('set j entry')\n",
    "                            b_bel = 0\n",
    "                            b_disbel = 0\n",
    "                            b_unc = 0\n",
    "                            print(x)\n",
    "#                             print(af.Consumerbel.tail(1))\n",
    "#                             print(af.Consumerdisbel.tail(1))\n",
    "#                             print(af.Consumerunc.tail(1))\n",
    "                            b_bel = af.Consumerbel.tail(1).item()\n",
    "                            b_disbel = af.Consumerdisbel.tail(1).item()\n",
    "                            b_unc = af.Consumerunc.tail(1).item()\n",
    "            \n",
    "                    nonsqrt=((a_bel - b_bel)**2) + ((a_disbel - b_disbel)**2) + ((a_unc - b_unc)**2)\n",
    "                    dist = nonsqrt** (1/2)\n",
    "                    dist = dist/2\n",
    "                    cum_dist += dist\n",
    "                print('searchin for vendor entries===end')\n",
    "                if len(comm_vendors) > 0:\n",
    "                    meand = cum_dist/len(comm_vendors)\n",
    "                    distance_matrix[idtoidx[j]][idtoidx[k]] = meand\n",
    "                    sim_matrix[idtoidx[j]][idtoidx[k]] = 1 - meand #Note that this would give 0 if no vendor since it initialize with 0\n",
    "                    cm_vendors[(j,k)] = comm_vendors\n",
    "                    com_ad.append(k)\n",
    "                \n",
    "                print('======mean distance beteween' +str(j) +' and '+str(k)+' = '+str(meand)+'======')\n",
    "                print('======sim' +str(j) +' and '+str(k)+' = '+str(1 - meand)+'======')\n",
    "        comv_advisors[j] = com_ad               \n",
    "        \n",
    "    return distance_matrix, sim_matrix, idxtoid, idtoidx, cm_vendors, comv_advisors\n",
    "\n",
    "\n",
    "##calling distance function\n",
    "d, sim, idx_id, id_idx, commonv, comv_advisors =distancematrix(df_dbu)\n",
    "\n",
    "\n",
    "# rep function\n",
    "def reputation3(df, sim, id_idx, idx_id, commonv, comv_advisors, user='Consumer', alpha=0.2):\n",
    "    uniqueid1list = df.Consumer.unique().tolist()\n",
    "    uniqueproducersl = df.Producer.unique().tolist()\n",
    "    rep_matrix = [[0 for i in range(len(uniqueid1list))] for j in range(len(uniqueproducersl))]\n",
    "    print(commonv)\n",
    "    \n",
    "    mf = df.groupby(['Consumer', 'Producer']) \n",
    "    pf = df.groupby(['Producer'])\n",
    "\n",
    "    \n",
    "    vidx_vid = {}\n",
    "    vid_vidx = {}\n",
    "    count = 0\n",
    "    for i in uniqueproducersl:\n",
    "        vidx_vid[count] = i\n",
    "        vid_vidx[i] = count #mostly used\n",
    "        count += 1\n",
    "    print(vidx_vid)\n",
    "    print(vid_vidx)\n",
    "    \n",
    "    v_neigbors = {}\n",
    "    for y, gf in pf:\n",
    "        print(gf.Consumer.unique())\n",
    "        v_neigbors[y] = gf.Consumer.unique().tolist()\n",
    "    \n",
    "\n",
    "    print('len(v_neigbors)'+str(len(v_neigbors)))\n",
    "    print('len(uniqueproducersl'+str(len(uniqueproducersl)))\n",
    "\n",
    "    vra_rep = {} #(vendor requestor advisor) = reputaion\n",
    "    for vendor in v_neigbors:\n",
    "#         print(key) \n",
    "        for requestor in uniqueid1list:\n",
    "#             print(v_neigbors[vendor])\n",
    "            hon = 0\n",
    "            rep = 0\n",
    "            hon_count = 0 #this is m in equation\n",
    "            rep_count = 0 #this in n in equation\n",
    "\n",
    "            for advisor in v_neigbors[vendor]:\n",
    "\n",
    "                if((advisor,requestor) in commonv):\n",
    "                    ab_sim = sim[id_idx[requestor]][id_idx[advisor]]\n",
    "                    cum_result = 0\n",
    "                    print('...commvl'+str((advisor,requestor)))\n",
    "                    for x, af in mf:\n",
    "                        if(x[0]==advisor and x[1]==vendor):\n",
    "                            av_bel = af.Consumerbel.tail(1).item()\n",
    "                            rep += (ab_sim * av_bel)\n",
    "                            rep_count += 1\n",
    "\n",
    "                else:\n",
    "                    print('no common pairs '+ str((advisor,requestor)))\n",
    "                    print('so we want '+ str(vendor)+' honesty with '+str(advisor))\n",
    "                \n",
    "                    for y, jf in mf: #in this loop following condition will occur only once\n",
    "                        if(y[0]==advisor and y[1]==vendor): \n",
    "                            av_bel = jf.Consumerbel.tail(1).item()\n",
    "                            va_hon = jf.honesty.tail(1).item()\n",
    "                            hon += (av_bel * va_hon)\n",
    "                            hon_count += 1\n",
    "            reputation = 0\n",
    "            if rep_count > 0:\n",
    "                reputation = (alpha * rep)/rep_count\n",
    "            \n",
    "            if hon_count > 0:\n",
    "                reputation += ((1 - alpha) * hon)/hon_count\n",
    "            \n",
    "            vra_rep[(vendor, requestor)] = reputation\n",
    "    return vra_rep\n",
    "\n",
    "\n",
    "##calling repfuction\n",
    "vendor_requestor_rep = reputation3(df_dbu, sim, id_idx, idx_id, commonv, comv_advisors)\n",
    "vendor_requestor_rep\n",
    "\n",
    "##initial trust\n",
    "##TODO setup trust_propensity for all users\n",
    "def init_trust(df, rep, beta=0.5):\n",
    "    requestor_li = df.Consumer.unique().tolist()\n",
    "    vendor_lis = df.Producer.unique().tolist()\n",
    "    rv_initT = {}\n",
    "    for vendor in vendor_lis:\n",
    "        for requestor in requestor_li:\n",
    "            trust_propensity = random.uniform(0, 1)\n",
    "            r = 0\n",
    "            if (vendor, requestor) in rep:\n",
    "                r = rep[(vendor, requestor)]\n",
    "            initT = (beta * trust_propensity ) + ((1-beta) * r)\n",
    "            rv_initT[(requestor,vendor)] = initT\n",
    "    return rv_initT\n",
    "\n",
    "##calling initrust\n",
    "intTrustm = init_trust(df_dbu, vendor_requestor_rep, beta)\n",
    "\n",
    "\n",
    "def trust_T(df,initT, beta=0.5):\n",
    "    mf = df.groupby(['Consumer', 'Producer'])\n",
    "    tDtDF = pd.DataFrame()\n",
    "    for k, af in mf:\n",
    "        print(k)\n",
    "        print(af)\n",
    "        trust_li = []\n",
    "        trust_dash_li = []\n",
    "        sum_test = []\n",
    "        t = 0\n",
    "        trust_propensity = random.uniform(0, 1)\n",
    "        for index, row in af.iterrows():\n",
    "            trust = 0\n",
    "            trust_dash = 0\n",
    "            sum_t = 0\n",
    "#             t = row['init_T'+str(user)]\n",
    "            if (k[1], k[0]) in initT:\n",
    "                t = initT[(k[1], k[0])]\n",
    "            b = row['Consumerbel']\n",
    "            d = row['Consumerdisbel']\n",
    "            u = row['Consumerunc']\n",
    "            trust = b + (t * u)\n",
    "            trust_dash = d + ((1 - t) * u) \n",
    "            sum_t = trust + trust_dash\n",
    "            print('sum_t')\n",
    "            print(sum_t)\n",
    "            trust_li.append(trust)\n",
    "            trust_dash_li.append(trust_dash)\n",
    "            sum_test.append(sum_t)\n",
    "\n",
    "        af['ConsumerT'] = trust_li\n",
    "        af['ConsumerT_dash'] = trust_dash_li\n",
    "        af['Consumersum_tdt'] = sum_test\n",
    "        print(af)\n",
    "        tDtDF = tDtDF.append(af, ignore_index = True)   \n",
    "    return tDtDF\n",
    "\n",
    "##final trust\n",
    "finDF = trust_T(df_dbu, intTrustm)\n",
    "\n",
    "##saving file\n",
    "if expinit:\n",
    "    filename = 'scenario_init'+str(scenario)+'_trust.csv'\n",
    "else:\n",
    "    \n",
    "    filename = 'scenario_final'+str(scenario)+'_trust.csv'\n",
    "\n",
    "finDF.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaka",
   "language": "python",
   "name": "anaka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
